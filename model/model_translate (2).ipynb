{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f8c7e79c",
      "metadata": {
        "id": "f8c7e79c"
      },
      "source": [
        "# -------------Giai đoạn 1: Xử lí dữ liệu-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e0d014f",
      "metadata": {
        "id": "1e0d014f"
      },
      "source": [
        "* Khai báo thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ed6e7b93",
      "metadata": {
        "id": "ed6e7b93"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import io\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ce8de3",
      "metadata": {
        "id": "58ce8de3"
      },
      "source": [
        "# 1. Load Tokenizer (Spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "34b6cca9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34b6cca9",
        "outputId": "7cc5ca0f-d555-4f09-b82c-3df92a9bf603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download fr_core_news_sm\n",
        "spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"Tách từ tiếng Anh, đảo ngược nếu cần (nhưng lúc này cứ để xuôi đê)\"\"\"\n",
        "    return [tok.text.lower() for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_fr(text):\n",
        "    \"\"\"Tách từ tiếng Pháp\"\"\"\n",
        "    return [tok.text.lower() for tok in spacy_fr.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "965f4e3b",
      "metadata": {
        "id": "965f4e3b"
      },
      "source": [
        "# 2. Xây dựng bộ từ vựng (Vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "9cfad0ba",
      "metadata": {
        "id": "9cfad0ba"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold=2):\n",
        "        # 4 token đặc biệt bắt buộc phải có\n",
        "        self.itos = {0: \"<unk>\", 1: \"<pad>\", 2: \"<sos>\", 3: \"<eos>\"}\n",
        "        self.stoi = {\"<unk>\": 0, \"<pad>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def build_vocabulary(self, sentence_list, tokenizer):\n",
        "        frequencies = Counter()\n",
        "        idx = 4 # Bắt đầu từ 4 vì 0-3 đã dùng cho token đặc biệt\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "            for word in tokenizer(sentence):\n",
        "                frequencies[word] += 1\n",
        "\n",
        "                # Chỉ thêm từ xuất hiện đủ nhiều (tránh rác)\n",
        "                if frequencies[word] == self.freq_threshold:\n",
        "                    self.stoi[word] = idx\n",
        "                    self.itos[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "    def numericalize(self, text, tokenizer):\n",
        "        \"\"\"Chuyển câu text thành list các số (indices)\"\"\"\n",
        "        tokenized_text = tokenizer(text)\n",
        "\n",
        "        return [\n",
        "            self.stoi[token] if token in self.stoi else self.stoi[\"<unk>\"]\n",
        "            for token in tokenized_text\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "496861d4",
      "metadata": {
        "id": "496861d4"
      },
      "source": [
        "# 3. Class Dataset Chính"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "93cb4219",
      "metadata": {
        "id": "93cb4219"
      },
      "outputs": [],
      "source": [
        "class Multi30kDataset(Dataset):\n",
        "    def __init__(self, root_dir, mode='train', src_vocab=None, trg_vocab=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.mode = mode\n",
        "\n",
        "        # Đọc file raw\n",
        "        en_path = os.path.join(root_dir, f'{mode}.en')\n",
        "        fr_path = os.path.join(root_dir, f'{mode}.fr')\n",
        "\n",
        "        with open(en_path, 'r', encoding='utf-8') as f:\n",
        "            self.source_sentences = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        with open(fr_path, 'r', encoding='utf-8') as f:\n",
        "            self.target_sentences = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        # Xây dựng hoặc dùng lại vocab\n",
        "        if src_vocab is None or trg_vocab is None:\n",
        "            print(f\" Đang xây dựng Vocabulary từ tập {mode}...\")\n",
        "            self.src_vocab = Vocabulary()\n",
        "            self.trg_vocab = Vocabulary()\n",
        "\n",
        "            self.src_vocab.build_vocabulary(self.source_sentences, tokenize_en)\n",
        "            self.trg_vocab.build_vocabulary(self.target_sentences, tokenize_fr)\n",
        "            print(f\" Vocab xong! Tiếng Anh: {len(self.src_vocab)} từ, Tiếng Pháp: {len(self.trg_vocab)} từ.\")\n",
        "        else:\n",
        "            self.src_vocab = src_vocab\n",
        "            self.trg_vocab = trg_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        src_text = self.source_sentences[index]\n",
        "        trg_text = self.target_sentences[index]\n",
        "\n",
        "        # Chuyển text sang số: <sos> ...câu... <eos>\n",
        "        src_numericalized = [self.src_vocab.stoi[\"<sos>\"]]\n",
        "        src_numericalized += self.src_vocab.numericalize(src_text, tokenize_en)\n",
        "        src_numericalized += [self.src_vocab.stoi[\"<eos>\"]]\n",
        "\n",
        "        trg_numericalized = [self.trg_vocab.stoi[\"<sos>\"]]\n",
        "        trg_numericalized += self.trg_vocab.numericalize(trg_text, tokenize_fr)\n",
        "        trg_numericalized += [self.trg_vocab.stoi[\"<eos>\"]]\n",
        "\n",
        "        return torch.tensor(src_numericalized), torch.tensor(trg_numericalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2d1a5c5",
      "metadata": {
        "id": "c2d1a5c5"
      },
      "source": [
        "# 4. Hàm Collate (Xử lý Batch - QUAN TRỌNG NHẤT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "628aa53b",
      "metadata": {
        "id": "628aa53b"
      },
      "outputs": [],
      "source": [
        "class Collate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # batch là list các cặp (src, trg) từ __getitem__\n",
        "\n",
        "        # Sắp xếp batch theo độ dài câu nguồn giảm dần (Bắt buộc cho pack_padded_sequence)\n",
        "        batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "        src_batch, trg_batch = zip(*batch)\n",
        "\n",
        "        # Padding: thêm số 1 (<pad>) vào cho bằng độ dài\n",
        "        src_padded = pad_sequence(src_batch, padding_value=self.pad_idx, batch_first=False) # Shape: [src_len, batch_size]\n",
        "        trg_padded = pad_sequence(trg_batch, padding_value=self.pad_idx, batch_first=False) # Shape: [trg_len, batch_size]\n",
        "\n",
        "        return src_padded, trg_padded"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe49467",
      "metadata": {
        "id": "7fe49467"
      },
      "source": [
        "# --------------GIAI ĐOẠN 2: XÂY DỰNG MODEL------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26ba78d",
      "metadata": {
        "id": "b26ba78d"
      },
      "source": [
        "* Khai báo thêm thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "2860d875",
      "metadata": {
        "id": "2860d875"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5c1cdd",
      "metadata": {
        "id": "1b5c1cdd"
      },
      "source": [
        "# 1. Mã hóa lớp Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "b7d587e2",
      "metadata": {
        "id": "b7d587e2"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Chuyển từ (số) sang vector\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        # LSTM: input_size=emb_dim, hidden_size=hid_dim\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src shape: [src len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded shape: [src len, batch size, emb dim]\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        # outputs: chứa hidden state của tất cả các time step (dùng cho Attention sau này)\n",
        "        # hidden, cell: trạng thái ẩn cuối cùng (Context Vector) -> Cần cho Decoder\n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c0d2b24",
      "metadata": {
        "id": "0c0d2b24"
      },
      "source": [
        "# 2. Giải mã (Decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "b0e6a450",
      "metadata": {
        "id": "b0e6a450"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Embedding cho Target (Tiếng Pháp)\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "\n",
        "        # Linear layer để dự đoán từ tiếp theo\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        # input shape: [batch size] (chỉ 1 từ tại 1 thời điểm)\n",
        "        # hidden, cell: context vector từ bước trước\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "        # input shape: [1, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded shape: [1, batch size, emb dim]\n",
        "\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        # output shape: [1, batch size, hid dim]\n",
        "\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        # prediction shape: [batch size, output dim]\n",
        "\n",
        "        return prediction, hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef286e6c",
      "metadata": {
        "id": "ef286e6c"
      },
      "source": [
        "# 3. Tạo mô hình Seq2Seq kết hợp Encoder và Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "0d1a94ba",
      "metadata": {
        "id": "0d1a94ba"
      },
      "outputs": [],
      "source": [
        "class MyTranslationModel(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "        # Check size cho chắc cú\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        # src: [src len, batch size]\n",
        "        # trg: [trg len, batch size]\n",
        "\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # Tensor chứa kết quả dự đoán\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # 1. Mã hóa câu nguồn (Encoder) -> Lấy context vector (hidden, cell)\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # 2. Đầu vào đầu tiên cho Decoder là token <sos> (Start of Sentence)\n",
        "        input = trg[0, :]\n",
        "\n",
        "        # 3. Vòng lặp giải mã từng từ (Decoder)\n",
        "        for t in range(1, trg_len):\n",
        "            # Chạy 1 bước decoder\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            # Lưu dự đoán vào tensor outputs\n",
        "            outputs[t] = output\n",
        "\n",
        "            # Quyết định Teacher Forcing:\n",
        "            # Nếu random < ratio -> dùng từ thật (target) làm input tiếp theo\n",
        "            # Ngược lại -> dùng từ dự đoán cao nhất (top1) làm input tiếp theo\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86949213",
      "metadata": {
        "id": "86949213"
      },
      "source": [
        "# --- TEST THỬ MODEL ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "f667715b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f667715b",
        "outputId": "13f54d80-0cd4-4034-a9ca-1a443e242d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Đang chạy thử model qua 1 vòng forward...\n",
            " Output Shape: torch.Size([26, 32, 1000])\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Giả lập tham số\n",
        "    INPUT_DIM = 1000\n",
        "    OUTPUT_DIM = 1000\n",
        "    ENC_EMB_DIM = 256\n",
        "    DEC_EMB_DIM = 256\n",
        "    HID_DIM = 512\n",
        "    N_LAYERS = 2\n",
        "    ENC_DROPOUT = 0.5\n",
        "    DEC_DROPOUT = 0.5\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "    model = MyTranslationModel(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "    # Giả lập input (như output của Dataset nãy chạy)\n",
        "    src = torch.randint(0, 1000, (24, 32)).to(DEVICE) # [Src Len, Batch Size]\n",
        "    trg = torch.randint(0, 1000, (26, 32)).to(DEVICE) # [Trg Len, Batch Size]\n",
        "\n",
        "    print(\" Đang chạy thử model qua 1 vòng forward...\")\n",
        "    output = model(src, trg)\n",
        "    print(f\" Output Shape: {output.shape}\")\n",
        "    # Mong đợi: [26, 32, 1000] -> [Trg Len, Batch Size, Output Dim]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d00cb27",
      "metadata": {},
      "source": [
        "# Code full train và đánh giá model trong model_train.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c557ff4",
      "metadata": {},
      "source": [
        "* Khai báo thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6015f4c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e64b6c2a",
      "metadata": {},
      "source": [
        "* CẤU HÌNH (CONFIG) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bd357c",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data_clean\" # Folder chứa data chuẩn\n",
        "BATCH_SIZE = 32         # CPU yếu thì để 32 hoặc 16 thôi\n",
        "N_EPOCHS = 10           # Chạy thử 5-10 epoch xem sao\n",
        "CLIP = 1.0              # Cắt gradient để không bị lỗi\n",
        "LR = 0.001              # Tốc độ học\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\" Đang chạy trên: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de25bd7",
      "metadata": {},
      "source": [
        "# 1. CHUẨN BỊ DỮ LIỆU "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f55f22",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\" Đang load dữ liệu...\")\n",
        "train_dataset = Multi30kDataset(DATA_DIR, mode='train')\n",
        "val_dataset = Multi30kDataset(DATA_DIR, mode='val', src_vocab=train_dataset.src_vocab, trg_vocab=train_dataset.trg_vocab)\n",
        "# test_dataset = Multi30kDataset(DATA_DIR, mode='test', src_vocab=train_dataset.src_vocab, trg_vocab=train_dataset.trg_vocab)\n",
        "\n",
        "pad_idx = train_dataset.src_vocab.stoi[\"<pad>\"]\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=Collate(pad_idx), num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=Collate(pad_idx), num_workers=0)\n",
        "\n",
        "print(f\" Data ngon lành! Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af4eee4",
      "metadata": {},
      "source": [
        "# 2. KHỞI TẠO MODEL "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2ff7e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_DIM = len(train_dataset.src_vocab)\n",
        "OUTPUT_DIM = len(train_dataset.trg_vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = MyTranslationModel(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "# Khởi tạo trọng số (Weight Initialization) - Giúp model học nhanh hơn\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "# Bỏ qua loss của token <pad>\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b13fc5",
      "metadata": {},
      "source": [
        "# 3. HÀM TRAIN & EVALUATE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bbb1a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # output: [trg len, batch size, output dim]\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        # Bỏ token <sos> đầu tiên khi tính loss\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradient để tránh bùng nổ\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Log nhẹ cái để biết máy không bị treo (mỗi 50 batch báo 1 lần)\n",
        "        if i % 50 == 0:\n",
        "            print(f\"   Batch {i}/{len(iterator)} | Loss: {loss.item():.3f}\")\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
        "            output = model(src, trg, teacher_forcing_ratio=0) # Tắt teacher forcing khi val/test\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc191dc",
      "metadata": {},
      "source": [
        "# 4. HÀM DỊCH THỬ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1217d4d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Tokenize & Numericalize\n",
        "    if isinstance(sentence, str):\n",
        "        import spacy\n",
        "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "        tokens = [token.text.lower() for token in spacy_en(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
        "    src_indexes = [src_vocab.stoi.get(token, src_vocab.stoi[\"<unk>\"]) for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device) # [len, 1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encoder\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    # Decoder\n",
        "    trg_indexes = [trg_vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device) # [1]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
        "    return trg_tokens[1:-1] # Bỏ sos, eos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6052f5b",
      "metadata": {},
      "source": [
        "# 5. VÒNG LẶP CHÍNH (MAIN LOOP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38011b6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "\n",
        "    # 1. CẤU HÌNH\n",
        "    DATA_DIR = \"data_clean\"\n",
        "\n",
        "    # --- KIỂM TRA AN TOÀN ---\n",
        "    # Nếu không thấy data thì báo lỗi dừng lại, CHỨ KHÔNG TỰ TẠO FILE MỚI NỮA\n",
        "    if not os.path.exists(os.path.join(DATA_DIR, 'train.en')):\n",
        "        print(\" LỖI TO: Không tìm thấy file dữ liệu!\")\n",
        "        exit() # Dừng chương trình ngay lập tức\n",
        "\n",
        "    # 2. Load Dataset (Chỉ đọc)\n",
        "    print(f\" Đang đọc dữ liệu từ {DATA_DIR}...\")\n",
        "    train_dataset = Multi30kDataset(DATA_DIR, mode='train')\n",
        "    val_dataset = Multi30kDataset(DATA_DIR, mode='val', src_vocab=train_dataset.src_vocab, trg_vocab=train_dataset.trg_vocab)\n",
        "\n",
        "    # Kiểm tra số lượng (Phải ~29000 mới đúng)\n",
        "    print(f\" Số lượng câu Train: {len(train_dataset)}\")\n",
        "    print(f\" Số lượng câu Val:   {len(val_dataset)}\")\n",
        "    print(f\" Vocab Size: Anh={len(train_dataset.src_vocab)}, Pháp={len(train_dataset.trg_vocab)}\")\n",
        "\n",
        "    # 3. Setup DataLoader\n",
        "    pad_idx = train_dataset.src_vocab.stoi[\"<pad>\"]\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=Collate(pad_idx), num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=Collate(pad_idx), num_workers=0)\n",
        "\n",
        "    # 4. Khởi tạo Model\n",
        "    INPUT_DIM = len(train_dataset.src_vocab)\n",
        "    OUTPUT_DIM = len(train_dataset.trg_vocab)\n",
        "\n",
        "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "    model = MyTranslationModel(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "    def init_weights(m):\n",
        "        for name, param in m.named_parameters():\n",
        "            nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "    model.apply(init_weights)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "    # 5. Bắt đầu Train\n",
        "    best_valid_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    print(f\"\\n Bắt đầu Train {N_EPOCHS} epochs (Dữ liệu thật)...\")\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "        valid_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(valid_loss)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"     Đã lưu model tốt nhất (Val Loss: {valid_loss:.3f})\")\n",
        "\n",
        "        print(f'Epoch: {epoch+1:02} | Time: {int(epoch_mins)}m {int(epoch_secs)}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')\n",
        "\n",
        "    # 6. Vẽ biểu đồ & Test\n",
        "    print(\"\\n Đang vẽ biểu đồ Loss...\")\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss_chart.png')\n",
        "    plt.show()\n",
        "\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    print(\"\\n Dịch thử 1 câu:\")\n",
        "    sentence = \"A man is walking a dog.\"\n",
        "    translation = translate_sentence(sentence, train_dataset.src_vocab, train_dataset.trg_vocab, model, DEVICE)\n",
        "    print(f\"Src: {sentence}\")\n",
        "    print(f\"Trg: {' '.join(translation)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
